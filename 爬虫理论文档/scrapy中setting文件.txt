设置最大并发数（默认是16）
# Configure maximum concurrent requests performed by Scrapy (default: 16)
#CONCURRENT_REQUESTS = 32

延迟（批量延迟）
#DOWNLOAD_DELAY = 3

禁用cookie
# Disable cookies (enabled by default)
#COOKIES_ENABLED = False

远程控制
# Disable Telnet Console (enabled by default)
#TELNETCONSOLE_ENABLED = False

默认请求头
# Override the default request headers:
#DEFAULT_REQUEST_HEADERS = {
#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
#   'Accept-Language': 'en',
#}

爬虫中间键
# Enable or disable spider middlewares
# See http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html
#SPIDER_MIDDLEWARES = {
#    'GitHub.middlewares.MyCustomSpiderMiddleware': 543,
#}

下载中间键
# Enable or disable downloader middlewares
# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html
#DOWNLOADER_MIDDLEWARES = {
#    'GitHub.middlewares.MyCustomDownloaderMiddleware': 543,
#}

扩展键
 Enable or disable extensions
# See http://scrapy.readthedocs.org/en/latest/topics/extensions.html
#EXTENSIONS = {
#    'scrapy.extensions.telnet.TelnetConsole': None,
#}

数据管道
# Configure item pipelines
# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html
#ITEM_PIPELINES = {
#    'GitHub.pipelines.SomePipeline': 300,
#}

设置日志
LOG_LEVEL = "WARNING" 
LOG_FILE = "github.log"

